{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### paper review assignment\n",
    "# Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolutional GANs을 안정화시킨 **DCGAN**을 소개한다.\n",
    "- classification에서 학습된 Discriminator를 사용한다.\n",
    "- 필터를 시각화한다.\n",
    "- 벡터 연산으로 다양한 샘플을 생성하는 Genernator를 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach and model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "핵심은 생성 이미지를 저해상도에서 업스케일하는 방식으로, 다음과 같은 특징을 가진다.\n",
    "\n",
    "1. pooling layer 변경  \n",
    "discriminator : strided convolutions(다운샘플링)  \n",
    "generator : fractional-strided convolutions(업샘플링)\n",
    "\n",
    "\n",
    "2. FC layer 제거 (global average pooling)  \n",
    "\n",
    "\n",
    "3. Batch Normalization로 모델 안정성 향상  \n",
    "generator output layer와 discriminator input layer 제외한 모든 layer에 적용\n",
    "\n",
    "\n",
    "4. generator의 output layer은 Tanh, 나머지는 ReLU 사용,  \n",
    "discriminator는 모두 Leaky ReLU 사용\n",
    "\n",
    "![텍스트](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F99BE854B5B41BA0B26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Details of adversarial training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 데이터 : LSUN,Imagenet-1k, Faces  \n",
    "- tanh 활성화함수 스케일링 외에 전처리 작업 없음\n",
    "- mini-batch size 128 SGD로 학습\n",
    "- N(0,0.02)로부터 weight initialize\n",
    "- LeakyReLU rate 0.2\n",
    "- Adam optimizer lr 0.0002, $\\beta1$ 0.5\n",
    "\n",
    "---\n",
    "\n",
    "LSUN : bedrooms 데이터셋 사용, over-fitting & memorization 입증\n",
    "\n",
    "FACES : 사람 얼굴이 포함된 이미지 데이터 사용, OpenCV face detector를 실행하여 고해상도 face boxes만 남김\n",
    "\n",
    "IMAGENET-1K: 비지도 학습을 위해 자연 이미지로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical validation of DCGANs capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DCGAN을 지도학습 데이터에 feature extractor로 사용하여 평가해보면 다음과 같다.\n",
    "\n",
    "CIFAR-10 데이터셋은 baseline K-means의 정확도가 80.6%인데, \n",
    "DCGAN에 Imagenet-1k를 학습하여 검증한 결과 82.8% 정확도를 보임 \n",
    "\n",
    "SVHN 데이터셋으로 라벨이 부족한 지도학습에서 DCGAN discriminator를 사용한 결과 test error 22.48%로 CNN 모델보다 나은 성능을 보임   \n",
    "또한 동일한 환경에서 CNN과의 비교를 통해 DCGAN에서 CNN 구조가 모델 아키텍처의 핵심 요소가 아님을 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating and visualizing the internals of the networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 잠재공간 latent space에서 이동이 부자연스러울 때, 즉 이미지에서 변화가 갑작스럽다면 memorization이 일어났다고 볼 수 있다. \n",
    "- DCGAN이 계층적으로 feature를 잘 잡는 것을 시각화를 통해 확인할 수 있다.\n",
    "- generator가 침대나 창문, 가구와 같은 구체적인 물체의 모습을 학습하는 것을 볼 수 있다. \n",
    "- 벡터 산술 연산을 얼굴 이미지에 적용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://leechamin.tistory.com/222\n",
    "- https://haawron.tistory.com/9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
