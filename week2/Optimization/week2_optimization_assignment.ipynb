{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tobig's 14ê¸° 2ì£¼ì°¨ Optimization ê³¼ì œ\n",
    "### Made by ì´ì§€ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "### 1) \"...\" í‘œì‹œë˜ì–´ ìˆëŠ” ë¹ˆ ì¹¸ì„ ì±„ì›Œì£¼ì„¸ìš”  \n",
    "### 2) ê°•ì˜ë‚´ìš©ê³¼ ì½”ë“œì— ëŒ€í•´ ê³µë¶€í•œ ë‚´ìš©ì„ ì ì–´ì„œ ê³¼ì œë¥¼ ì±„ì›Œì£¼ì„¸ìš”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>48000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>76000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label  bias  experience  salary\n",
       "0      1     1         0.7   48000\n",
       "1      0     1         1.9   48000\n",
       "2      1     1         2.5   60000\n",
       "3      0     1         4.2   63000\n",
       "4      0     1         6.0   76000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('assignment_2.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test ë°ì´í„° ë‚˜ëˆ„ê¸°\n",
    "### ë°ì´í„°ì…‹ì„ train/testë¡œ ë‚˜ëˆ ì£¼ëŠ” ë©”ì†Œë“œ  \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:, 1:], data.iloc[:, 0], test_size=0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 3), (50, 3), (150,), (50,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling  \n",
    "\n",
    "experienceì™€ salaryì˜ ë‹¨ìœ„, í‰ê· , ë¶„ì‚°ì´ í¬ê²Œ ì°¨ì´ë‚˜ë¯€ë¡œ scalerë¥¼ ì‚¬ìš©í•´ ë‹¨ìœ„ë¥¼ ë§ì¶°ì¤ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187893</td>\n",
       "      <td>-1.143335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.185555</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>-0.351795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.629277</td>\n",
       "      <td>-1.341220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.308600</td>\n",
       "      <td>0.043974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1    0.187893 -1.143335\n",
       "1     1    1.185555  0.043974\n",
       "2     1   -0.310938 -0.351795\n",
       "3     1   -1.629277 -1.341220\n",
       "4     1   -1.308600  0.043974"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "bias_train = X_train[\"bias\"]\n",
    "bias_train = bias_train.reset_index()[\"bias\"]\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_train[\"bias\"] = bias_train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ë•Œ scalerëŠ” X_trainì— fit í•´ì£¼ì‹œê³ , fití•œ scalerë¥¼ X_testì— ì ìš©ì‹œì¼œì¤ë‹ˆë‹¤.  \n",
    "ë˜‘ê°™ì´ X_testì—ë‹¤ fití•˜ë©´ ì•ˆë¼ìš”!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>experience</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.344231</td>\n",
       "      <td>-0.615642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.508570</td>\n",
       "      <td>0.307821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.310938</td>\n",
       "      <td>0.571667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.363709</td>\n",
       "      <td>1.956862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.987923</td>\n",
       "      <td>-0.747565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bias  experience    salary\n",
       "0     1   -1.344231 -0.615642\n",
       "1     1    0.508570  0.307821\n",
       "2     1   -0.310938  0.571667\n",
       "3     1    1.363709  1.956862\n",
       "4     1   -0.987923 -0.747565"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_test = X_test[\"bias\"]\n",
    "bias_test = bias_test.reset_index()[\"bias\"]\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "X_test[\"bias\"] = bias_test\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter ê°œìˆ˜\n",
    "N = len(X_train.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96726719, 0.37331064, 0.11774316])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì´ˆê¸° parameterë“¤ì„ ì„ì˜ë¡œ ì„¤ì •í•´ì¤ë‹ˆë‹¤.\n",
    "parameters = np.array([random.random() for i in range(N)])\n",
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * LaTeX   \n",
    "\n",
    "Jupyter Notebookì€ LaTeX ë¬¸ë²•ìœ¼ë¡œ ìˆ˜ì‹ ì…ë ¥ì„ ì§€ì›í•˜ê³  ìˆìŠµë‹ˆë‹¤.  \n",
    "http://triki.net/apps/3466  \n",
    "https://jjycjnmath.tistory.com/117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Function\n",
    "\n",
    "## $p = 1/(1+e^{âˆ’ğ‘‹ğœƒ})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic(X, parameters):\n",
    "    z = 0\n",
    "    for i in range(len(parameters)) :\n",
    "        z += parameters[i]*X[i]\n",
    "    p = 1/(1+np.exp(-z))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8045573467928063"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic(X_train.iloc[1], parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Function\n",
    "\n",
    "Object Function : ëª©ì í•¨ìˆ˜ëŠ” Gradient Descentë¥¼ í†µí•´ ìµœì í™” í•˜ê³ ì í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.  \n",
    "ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ëª©ì í•¨ìˆ˜ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”\n",
    "## $l(p) =-\\sum\\{y_ilogp+(1-y_i)log(1-p)\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_i(X, y, parameters) :\n",
    "    p = logistic(X, parameters)              # ìœ„ì—ì„œ ì‘ì„±í•œ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì„¸ìš”\n",
    "    loss = (y*np.log(p)+(1-y)*np.log(1-p))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(X_set, y_set, parameters) :\n",
    "    loss = 0\n",
    "    for i in range(X_set.shape[0]):\n",
    "        X = X_set.iloc[i, :]\n",
    "        y = y_set.iloc[i]\n",
    "        loss += cross_entropy_i(X, y, parameters)\n",
    "    return -loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.9528669996735"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(X_test, y_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient of Cross Entropy\n",
    "\n",
    "## ${\\partial\\over{\\partial \\theta_j}}l(p)= -\\sum(y_i-p)x_{ij}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropyë¥¼ theta_jì— ëŒ€í•´ ë¯¸ë¶„í•œ ê°’ì„ êµ¬í•˜ëŠ” í•¨ìˆ˜\n",
    "def get_gradient_ij_cross_entropy(X, y, parameters, j):\n",
    "    p = logistic(X, parameters)\n",
    "    gradient = -((y-p)*X[j].sum())\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05420292075340681"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gradient_ij_cross_entropy(X_train.iloc[0, :], y_train.iloc[0], parameters, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Gradient Descent  \n",
    "\n",
    "Batch Gradient Descent : í•™ìŠµ í•œ ë²ˆì— ëª¨ë“  ë°ì´í„°ì…‹ì— ëŒ€í•´ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients_bgd(X_train, y_train, parameters) :\n",
    "    gradients = [0 for i in range(len(parameters))]\n",
    "    \n",
    "    for i in range(len(X_train)):  ## ëª¨ë“  ë°ì´í„°ì…‹ì— ëŒ€í•˜ì—¬ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•˜ë¯€ë¡œ í–‰ì˜ í¬ê¸°ë§Œí¼ ë°˜ë³µë¬¸ í•„ìš”\n",
    "        X = X_train.iloc[i, :]\n",
    "        y = y_train.iloc[i]\n",
    "        for j in range(len(parameters)):\n",
    "            gradients[j] += get_gradient_ij_cross_entropy(X, y, parameters, j)\n",
    "            \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[65.26839629122074, -4.707506947891669, 25.42748495236561]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_bgd = get_gradients_bgd(X_train, y_train, parameters)\n",
    "gradients_bgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent  \n",
    "\n",
    "Stochastic Gradient Descent : í•™ìŠµ í•œ ë²ˆì— ì„ì˜ì˜ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ê¸°ìš¸ê¸°ë¥¼ êµ¬í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients_sgd(X_train, y, parameters) :\n",
    "    gradients = [0 for i in range(len(parameters))]\n",
    "    r = int(random.random()*len(X_train))  ## ì„ì˜ì˜ ë°ì´í„°ì…‹ í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ë§Œ í•„ìš”í•˜ë¯€ë¡œ 0~nì¤‘ì— ëœë¤í•˜ê²Œ ë½‘ê¸° ìœ„í•´ ë°ì´í„° ê¸¸ì´ë¥¼ ê³±í•´ì¤Œ\n",
    "    X = X_train.iloc[r, :]\n",
    "    y = y_train.iloc[r]\n",
    "        \n",
    "    for j in range(len(parameters)):\n",
    "        gradients[j] = get_gradient_ij_cross_entropy(X, y, parameters, j)\n",
    "        \n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5770890888298423, -0.734616758789803, -0.8882005564435079]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients_sgd = get_gradients_sgd(X_train, y_train, parameters)\n",
    "gradients_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, gradients, learning_rate) :\n",
    "    for i in range(len(parameters)) :\n",
    "        gradients[i] *= learning_rate  ## í•™ìŠµë¥ ì„ í•˜ë‚˜ì”© ê³±í•´ì•¼í•´ì„œ ë°˜ë³µë¬¸ìœ¼ë¡œ ëŒë¦¬ëŠ” ê²ƒ\n",
    "    parameters -= gradients\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31458322,  0.42038571, -0.13653169])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_parameters(parameters, gradients_bgd, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent  \n",
    "\n",
    "ìœ„ì—ì„œ ì‘ì„±í•œ í•¨ìˆ˜ë“¤ì„ ì¡°í•©í•´ì„œ Gradient Descentë¥¼ ì§„í–‰í•˜ëŠ” í•¨ìˆ˜ë¥¼ ì™„ì„±í•´ì£¼ì„¸ìš”\n",
    "\n",
    "learning_rate = í•™ìŠµë¥   \n",
    "max_iter = ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜  \n",
    "tolerance = step ì´ë™ì´ ë¬´ì˜ë¯¸í•  ì‹œ ì¤‘ë‹¨ ì¡°ê±´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X_train, y_train, learning_rate=0.01, max_iter=100000, tolerance=0.0001, optimizer=\"bgd\") :\n",
    "    count = 1\n",
    "    point = 100 if optimizer == \"bgd\" else 10000  ## pointì— ë„ë‹¬í•  ë•Œë§ˆë‹¤ í•™ìŠµì„ ì¤‘ë‹¨í•´ì•¼ í• ì§€ ì ê²€í•˜ê¸° ìœ„í•œ ì§€ì \n",
    "    N = len(X_train.iloc[0])\n",
    "    parameters = np.array([random.random() for i in range(N)])\n",
    "    gradients = [0 for i in range(N)]\n",
    "    loss = 0\n",
    "    \n",
    "    while count < max_iter :\n",
    "        \n",
    "        if optimizer == \"bgd\" :\n",
    "            gradients = get_gradients_bgd(X_train, y_train, parameters)\n",
    "        elif optimizer == \"sgd\" :\n",
    "            gradients = get_gradients_sgd(X_train, y_train, parameters)\n",
    "            # loss, ì¤‘ë‹¨ í™•ì¸\n",
    "        if count%point == 0 :\n",
    "            new_loss = cross_entropy(X_train, y_train, parameters)\n",
    "            print(count, \"loss: \",new_loss, \"params: \", parameters, \"gradients: \", gradients)\n",
    "            \n",
    "            #ì¤‘ë‹¨ ì¡°ê±´\n",
    "            if abs(new_loss-loss) < tolerance/len(y_train) : ## stepì˜ ì´ë™ì´ ë”ì´ìƒ ì˜ë¯¸ì—†ì„ ë•Œ, ì¦‰ loss ê°’ì˜ ë³€ë™ì´ ê·¹íˆ ì‘ì„ ë•Œ ì¤‘ë‹¨\n",
    "                break\n",
    "            loss = new_loss\n",
    "                \n",
    "            \n",
    "                \n",
    "        parameters = update_parameters(parameters, gradients, learning_rate)\n",
    "        count += 1\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loss:  45.34382296890982 params:  [-1.63080242  3.49713612 -3.32195088] gradients:  [0.26749435207169003, -0.8796193985760208, 0.821816857490237]\n",
      "200 loss:  44.796957196080434 params:  [-1.78402755  3.99778559 -3.78729337] gradients:  [0.08117329288182086, -0.26374123929981536, 0.2438797218408273]\n",
      "300 loss:  44.73979724502206 params:  [-1.83482536  4.16258409 -3.9394377 ] gradients:  [0.029286796375830218, -0.09487102111523638, 0.08744442911973072]\n",
      "400 loss:  44.73206145253853 params:  [-1.85364447  4.22351504 -3.99556646] gradients:  [0.011140461925200393, -0.03605096342926666, 0.03319010447485067]\n",
      "500 loss:  44.730926353032494 params:  [-1.86087105  4.24689604 -4.01708729] gradients:  [0.004319077450530895, -0.01397130479509539, 0.012856884805586229]\n",
      "600 loss:  44.730754834614245 params:  [-1.86368277  4.25599071 -4.02545581] gradients:  [0.0016866020873587684, -0.005454990242893851, 0.005019008568629663]\n",
      "700 loss:  44.73072862593418 params:  [-1.86478227  4.25954673 -4.02872752] gradients:  [0.0006604624014636962, -0.0021360148280015895, 0.001965164906943255]\n",
      "800 loss:  44.73072460373211 params:  [-1.86521306  4.26093994 -4.03000927] gradients:  [0.0002589151019825042, -0.0008373435795721931, 0.0007703480508796517]\n",
      "900 loss:  44.730723985404516 params:  [-1.86538198  4.26148621 -4.03051184] gradients:  [0.00010154351240777848, -0.00032839356082731835, 0.00030211580108410047]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.86538198,  4.26148621, -4.03051184])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_bgd = gradient_descent(X_train, y_train)\n",
    "new_param_bgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning\n",
    "\n",
    "Hyper Parameterë“¤ì„ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ í•´ì„œ í•™ìŠµì„ ì§„í–‰í•´ ë³´ì„¸ìš”. ë‹¤ë¥¸ ì ë“¤ì„ ë°œê²¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loss:  46.566150611712494 params:  [-1.48015943  2.98794247 -2.97642657] gradients:  [0.0315230947433199, -0.023280043145461705, -0.0027724197017444563]\n",
      "20000 loss:  45.22598610387789 params:  [-1.80570804  3.79609453 -3.46108401] gradients:  [-0.7089966080074461, -0.966865170457979, -0.8729760363699444]\n",
      "30000 loss:  44.824287123695065 params:  [-1.72269429  4.07366769 -3.83298193] gradients:  [0.3165290704908505, 0.5782699509424195, 0.5358885346829997]\n",
      "40000 loss:  44.86891536798804 params:  [-1.69729517  4.13342361 -3.91259882] gradients:  [0.16249207208203628, -0.1431605049925162, -0.15362813918245]\n",
      "50000 loss:  44.744931549010886 params:  [-1.87928988  4.20204878 -3.95865675] gradients:  [-0.6804647850906472, 0.5510193721978272, 0.7779991747183738]\n",
      "60000 loss:  44.736239580450764 params:  [-1.87718671  4.32723472 -4.07068442] gradients:  [0.0014067523685090432, -0.0016403816358342724, -0.00012372224280919074]\n",
      "70000 loss:  44.87301985087269 params:  [-1.82329766  4.26619929 -4.16439816] gradients:  [-0.2156286884501868, -0.12502835934966436, 0.03318751381263959]\n",
      "80000 loss:  44.82284513871488 params:  [-1.77989184  4.20293977 -4.05874859] gradients:  [0.711894756218493, -0.8301241290854987, -1.330469298947808]\n",
      "90000 loss:  44.77375352556433 params:  [-1.92979908  4.21268734 -4.00488912] gradients:  [-0.29877388246934977, -0.32227628156729665, -0.13138408599622628]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.89892211,  4.19774877, -3.99997805])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_param_sgd = gradient_descent(X_train, y_train, learning_rate=0.01, max_iter=100000, tolerance=0.0001, optimizer=\"sgd\")\n",
    "new_param_sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "for i in range(len(y_test)):\n",
    "    p = logistic(X_test.iloc[i,:], new_param_bgd)\n",
    "    if p> 0.5 :\n",
    "        y_predict.append(1)\n",
    "    else :\n",
    "        y_predict.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 1,  9]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "confusion_matrix(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428572"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì •í™•ë„ëŠ” 0.94, f1 scoreëŠ” 0.857ë¡œ, TNì˜ ë¹„ì¤‘ì´ ë†’ì•„ imbalanceë¡œ ì¸í•´ f1 scoreê°€ ì¡°ê¸ˆ ë‚®ê²Œ ë‚˜ì˜¤ê¸´ í–ˆìœ¼ë‚˜, ì „ë°˜ì ìœ¼ë¡œ ì˜ ì˜ˆì¸¡í–ˆë‹¤ê³  í‰ê°€í•  ìˆ˜ ìˆìŒ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
