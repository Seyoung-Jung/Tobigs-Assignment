{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3-final"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "assignment_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Seyoung-Jung/Tobigs-HW/blob/master/week4/SVM/assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HyMvTfrPTEU",
        "colab_type": "text"
      },
      "source": [
        "#### TOBIG'S 14기 정규세션 4주차 SVM \n",
        "### ASSIGNMENT1. Multiclass SVM 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMqxwjbRNX6u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "c2ef6051-62da-40b5-d6b2-3bea292ea312"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#IRIS 데이터 로드\n",
        "iris =  sns.load_dataset('iris') \n",
        "X= iris.iloc[:,:4] #학습할데이터\n",
        "y = iris.iloc[:,-1] #타겟\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0         setosa\n",
            "1         setosa\n",
            "2         setosa\n",
            "3         setosa\n",
            "4         setosa\n",
            "         ...    \n",
            "145    virginica\n",
            "146    virginica\n",
            "147    virginica\n",
            "148    virginica\n",
            "149    virginica\n",
            "Name: species, Length: 150, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2clcWctDvu0",
        "colab_type": "text"
      },
      "source": [
        "모델에 학습시킬 땐 train 데이터만 사용하므로 test 데이터와 split한 뒤에 scaling 해줘야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyMSHOFHNX7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split #test/train 데이터로 분리\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsSN17XTITLW",
        "colab_type": "text"
      },
      "source": [
        "X_train 데이터에 fit하여 scaling한 후에, fit한 scaler를 X_test에 적용시켜주어야 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tm8gpfVSNX67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scal = StandardScaler() #scaling\n",
        "X_train = scal.fit_transform(X_train)\n",
        "X_test = scal.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KnlaqAJNX7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = pd.get_dummies(y_train) #one hot encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7VgXR-SNX7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One VS Rest 구현을 위해 1) class가 0 or not 2)class가 1 or not을 구분하기 위한 머신 등을 미리 만들어주자\n",
        "svm_1 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
        "svm_2 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
        "svm_3 = SVC(kernel ='rbf', C = 5, gamma = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S5ML8x1NX7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "55542679-dc31-454c-b102-88d9f433ef49"
      },
      "source": [
        "svm_1.fit(X_train,y_train.iloc[:,0]) # 데이터 클레스가 0 or not 구분해주는 머신\n",
        "svm_2.fit(X_train,y_train.iloc[:,1]) # 데이터 클레스가 1 or not 구분해주는 머신\n",
        "svm_3.fit(X_train,y_train.iloc[:,2]) # 데이터 클레스가 2 or not 구분해주는 머신\n",
        "print(svm_1.predict(X_test)) #데이터 클래스가 0 or not을 구분해주는 애를 통해서 테스트 데이터의 클래스가 0인지, 0이 아닌인지 예측해보자\n",
        "\n",
        "print(svm_1.decision_function(X_test)) #decision_function hyperplane과의 거리를 구하는 방법(필요하다면 활용해주세요!)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0]\n",
            "[-1.12359969 -0.86782512 -0.65599247 -0.50194294 -0.76541147 -0.8819188\n",
            "  1.07735938 -0.99156769  0.50201986 -0.9984315  -0.84532712  0.17062549\n",
            "  0.34917127 -0.9813287  -0.72783399 -0.93313988  1.28153212 -0.56827872\n",
            " -0.73092732 -0.99670034  0.43553308 -0.96967771 -0.83939495 -1.03305682\n",
            " -0.75566609  1.13888006  0.42965012 -1.04268452 -0.93608147 -1.06090982]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCR46aMrNX7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "20dced8f-3e79-4a0d-bd73-b008c603e792"
      },
      "source": [
        "# 부호가 모든 같은 경우가 있는가? > 모두 동점인 경우가 생길 것\n",
        "for i in range(len(X_test)):\n",
        "    # ~. decision_function을 이용하면 해당 데이터가 하이퍼플레인으로부터 얼마나 떨어져있는지 '거리'가 나온다!\n",
        "    # 다음은 그 값의 부호를 이용해 모두가 동점인 경우가 있는지 출력하는 함수 \n",
        "    if (np.sign(svm_1.decision_function(X_test)[i]) == np.sign(svm_2.decision_function(X_test)[i])) and (np.sign(svm_2.decision_function(X_test)[i]) == \n",
        "    np.sign(svm_3.decision_function(X_test)[i])):\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "17\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CSyGRow_Vosc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c89e9d89-6f36-451c-e5f3-7a23c8129c93"
      },
      "source": [
        "## Case 1 : One vs Rest SVM을 이부분에 구현해주세요 위 결과들을 이용해서 multi class SVM을 직접 구현해주세요! 하드코딩이 하시기 편할겁니다.\n",
        "y_pred = []\n",
        "predict_1 = svm_1.predict(X_test)\n",
        "predict_2 = svm_2.predict(X_test)\n",
        "predict_3 = svm_3.predict(X_test)\n",
        "distance_1 = svm_1.decision_function(X_test)\n",
        "distance_2 = svm_2.decision_function(X_test)\n",
        "distance_3 = svm_3.decision_function(X_test)\n",
        "\n",
        "for i in range(len(X_test)):  # test 데이터 하나씩 예측한 결과를 y_pred에 담는다.\n",
        "    setosa =predict_1[i]       # setosa이면 1, 아니면 0\n",
        "    versicolor = predict_2[i]   # versicolor이면 1, 아니면 0\n",
        "    virginica = predict_3[i]    # virginica이면 1, 아니면 0\n",
        "    if (setosa + versicolor + virginica)==1:  # 셋 중에 하나만 맞다고 예측한 경우\n",
        "        if setosa==1:y_pred.append('setosa')\n",
        "        elif versicolor==1:y_pred.append('versicolor')\n",
        "        else:y_pred.append('virginica')\n",
        "    else:                                     # 동점과 같은 상황으로 인해 바로 하나의 클래스로 판단할 수 없는 경우\n",
        "        distance = [np.abs(distance_1[i]), np.abs(distance_2[i]), np.abs(distance_3[i])]  # distance는 이 test 데이터의 각 초평면까지의 거리를 담는다.\n",
        "        min_distance = distance.index(min(distance))                 # distance가 가장 짧은 클래스의 인덱스를 구해 예측 결과로 판단한다.\n",
        "        if min_distance==0:y_pred.append('setosa')\n",
        "        elif min_distance==1:y_pred.append('versicolor')\n",
        "        else:y_pred.append('virginica')\n",
        "\n",
        "from sklearn import metrics\n",
        "print(y_pred)\n",
        "print(metrics.accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n",
            "0.8666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ71EIvQNX71",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "90617cd6-4896-481e-dfcd-b1d86c3df46d"
      },
      "source": [
        "# Case 2 : One vs One SVM을 이 부분에 구현해주세요. (선택사항)\n",
        "from collections import Counter\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=48)\n",
        "scal = StandardScaler() #scaling\n",
        "X_train = scal.fit_transform(X_train)\n",
        "X_test = scal.transform(X_test)   # one-hot encoding을 하지 않은 원래 y_train 데이터를 사용하기 위해 split과 scaling을 다시 해준다.\n",
        "X_train = (pd.DataFrame(X_train).reset_index()).drop(['index'],axis=1)  # split할 때 원래 데이터의 인덱스를 끌고 오므로 이를 없애기 위해 reset_index() 후 'index' 열을 제거한다.\n",
        "y_train = (pd.DataFrame(y_train).reset_index()).drop(['index'],axis=1)\n",
        "\n",
        "row01 = y_train[(y_train.species=='setosa') | (y_train.species=='versicolor')].index  # y가 두 클래스에 해당하는 행만(120행 중에 약 80행) 가져와야 학습이 가능하므로 row 인덱스를 저장한다.\n",
        "row02 = y_train[(y_train.species=='setosa') | (y_train.species=='virginica')].index\n",
        "row12 = y_train[(y_train.species=='versicolor') | (y_train.species=='virginica')].index\n",
        "\n",
        "svm_01 = SVC(kernel ='rbf', C = 5, gamma = 5).fit(X_train.iloc[row01,:],y_train.iloc[row01])\n",
        "svm_02 = SVC(kernel ='rbf', C = 5, gamma = 5).fit(X_train.iloc[row02,:],y_train.iloc[row02])\n",
        "svm_12 = SVC(kernel ='rbf', C = 5, gamma = 5).fit(X_train.iloc[row12,:],y_train.iloc[row12])\n",
        "\n",
        "y_pred = []\n",
        "predict_01 = svm_01.predict(X_test)\n",
        "predict_02 = svm_02.predict(X_test)\n",
        "predict_12 = svm_12.predict(X_test)\n",
        "for i in range(len(X_test)):\n",
        "    compitition = [predict_01[i], predict_02[i], predict_12[i]]  # 세 가지 예측 결과를 저장한다. 1:1 모델이 3개라 동점이 나오는 경우는 고려할 필요가 없다.\n",
        "    y_pred.append(Counter(compitition).most_common(1)[0][0])  # 가장 많이 승리한 클래스 최종 투표 결과를 y_pred에 넣어준다.\n",
        "\n",
        "print(y_pred)\n",
        "metrics.accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica', 'virginica', 'setosa', 'virginica', 'setosa', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'versicolor', 'versicolor', 'setosa', 'versicolor', 'virginica', 'virginica', 'setosa', 'virginica', 'versicolor', 'versicolor', 'virginica', 'setosa', 'setosa', 'virginica', 'virginica', 'versicolor']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlVlC9l9NX77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1d414916-a4a9-4024-ff97-193022d01d29"
      },
      "source": [
        "# 원래 라이브러리가 제공하는 multi class SVM과 여러분이 구현한 multiclass SVM 결과를 비교해주세요\n",
        "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X, y, test_size=0.2, random_state=48)\n",
        "\n",
        "svm_4 = SVC(kernel ='rbf', C = 5, gamma = 5)\n",
        "svm_4.fit(X_train_2, y_train_2)\n",
        "y_pred = svm_4.predict(X_test_2)\n",
        "\n",
        "print(y_pred)\n",
        "metrics.accuracy_score(y_test_2,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['versicolor' 'versicolor' 'virginica' 'virginica' 'virginica' 'virginica'\n",
            " 'setosa' 'virginica' 'setosa' 'versicolor' 'virginica' 'setosa' 'setosa'\n",
            " 'virginica' 'versicolor' 'versicolor' 'setosa' 'versicolor' 'virginica'\n",
            " 'virginica' 'setosa' 'virginica' 'virginica' 'versicolor' 'virginica'\n",
            " 'setosa' 'setosa' 'virginica' 'virginica' 'versicolor']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPWTNmWsCym8",
        "colab_type": "text"
      },
      "source": [
        "One vs Rest와 One vs One, 기존 라이브러리에서 제공하는 multi class SVM 모두 0.8667의 동일한 정확도를 보였다. 각각 하나씩 비교해보면 한 두개 다른 경우가 있지만 결과적으로 모두 동일한 예측 능력을 보이고 있다."
      ]
    }
  ]
}